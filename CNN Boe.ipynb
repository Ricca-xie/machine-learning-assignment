{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# package\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr\n",
    "import pdb\n",
    "from keras.optimizers import SGD\n",
    "# Machine learning package\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import talib as ta\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.wrappers import scikit_learn\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "def scale_list(l, to_min, to_max):\n",
    "    # map the number in l to [to_min, to_max]\n",
    "    # step1: map the number in l to [0, 1]\n",
    "    # step2: multiply the new l in step 1 by (to_max - to_min)\n",
    "    def scale_number(unscaled, to_min, to_max, from_min, from_max):\n",
    "        return (to_max-to_min)*(unscaled-from_min)/(from_max-from_min)+to_min\n",
    "\n",
    "    if len(set(l)) == 1:\n",
    "        return [np.floor((to_max + to_min)/2)] * len(l)\n",
    "    else:\n",
    "        return [scale_number(i, to_min, to_max, min(l), max(l)) for i in l]\n",
    "\n",
    "# Get classification report    \n",
    "def get_performance(report,aoc,model_score):    \n",
    "    index = {'-1','1','macro avg','weighted avg'}\n",
    "    index2 = {'accuracy'}\n",
    "    test_1 = {key:value for key,value in report.items() if key in index}\n",
    "    report2 = pd.DataFrame(test_1)\n",
    "    report3 = pd.DataFrame([report['accuracy'],aoc], index=['accuracy','AUC'])\n",
    "    print(report2)\n",
    "    print(report3)\n",
    "    return report2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOCKS = ['AAPL','AXP','BA','CAT','CSCO']#,'CVX','DIS','DD','GE','GS','HD','IBM','INTC','JNJ','JPM','KO','MCD','MMM','MRK','MSFT','NKE','PFE','PG','TRV','UNH','UTX','V','VZ','WMT','XOM'\n",
    "\n",
    "tot_stocks = len(STOCKS)\n",
    "\n",
    "TIME_RANGE = 20 # x-axis in the image\n",
    "PRICE_RANGE = 20 # y-axis in the image\n",
    "VALIDTAION_CUTOFF_DATE = datetime.date(2017, 7, 1)\n",
    "\n",
    "\n",
    "# split image horizontally into two sections - top and bottom sections\n",
    "# we scale the price / moving avg price to the range [0 10]\n",
    "# image has two parts:\n",
    "# top: \n",
    "#     x : past 20 days\n",
    "#     y : close price and moving average price, range:[0, 10]\n",
    "# bottom:\n",
    "#     x : past 20 days\n",
    "#     y : close - open, range : [0, 10]\n",
    "\n",
    "half_scale_size = int(PRICE_RANGE/2)\n",
    " \n",
    "live_symbols = []\n",
    "x_live = None\n",
    "x_train = None\n",
    "x_valid = None\n",
    "y_train = []\n",
    "y_valid = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing stock AAPL (0 / 5)\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "\tfinished processing 500 trading dates for stock AAPL\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "processing stock AXP (1 / 5)\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "\tfinished processing 500 trading dates for stock AXP\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "processing stock BA (2 / 5)\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "\tfinished processing 500 trading dates for stock BA\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "processing stock CAT (3 / 5)\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "\tfinished processing 500 trading dates for stock CAT\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "processing stock CSCO (4 / 5)\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "\tfinished processing 500 trading dates for stock CSCO\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n"
     ]
    }
   ],
   "source": [
    "cnt_stock = 0\n",
    "\n",
    "for stock in STOCKS:\n",
    "    print('processing stock {} ({} / {})'.format(stock, str(cnt_stock), str(tot_stocks)))\n",
    "    cnt_stock += 1\n",
    "\n",
    "    # build image data for this stock\n",
    "    # stock_data = pdr.get_data_google(stock)\n",
    "    # download dataframe\n",
    "    stock_data = pdr.get_data_yahoo(stock, start=\"2016-01-01\", end=\"2018-01-17\")\n",
    "\n",
    "    stock_data['Symbol'] = stock\n",
    "    stock_data['S_10'] = stock_data['Close'].rolling(window=3).mean()\n",
    "    stock_data['MOM']= ta.MOM(stock_data.Close, timeperiod=5)\n",
    "    stock_data['Date'] = stock_data.index\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'], infer_datetime_format=True)\n",
    "    stock_data['Date'] = stock_data['Date'].dt.date#获取data部分\n",
    "    stock_data = stock_data.reset_index(drop=True)\n",
    " \n",
    "    # add Moving Averages to all lists and back fill resulting first NAs to last known value\n",
    "    noise_ma_smoother = 3\n",
    "    stock_closes = stock_data['Close'].rolling(window = noise_ma_smoother).mean()\n",
    "    stock_closes = stock_closes.fillna(method='bfill')  \n",
    "    stock_closes =  list(stock_closes.values)\n",
    "    stock_opens = stock_data['Open'].rolling(window = noise_ma_smoother).mean()\n",
    "    stock_opens = stock_opens.fillna(method='bfill')  \n",
    "    stock_opens =  list(stock_opens.values)\n",
    "    stock_s10 = list(stock_data['S_10'].values)\n",
    "    stock_mom = list(stock_data['MOM'].values)\n",
    "    \n",
    "    stock_dates = stock_data['Date'].values \n",
    "  \n",
    "    close_minus_open = list(np.array(stock_closes) - np.array(stock_opens))\n",
    "\n",
    "    # lets add a rolling average as an overlay indicator - back fill the missing\n",
    "    # first five values with the first available avg price\n",
    "    longer_ma_smoother = 6\n",
    "    stock_closes_rolling_avg = stock_data['Close'].rolling(window = longer_ma_smoother).mean()\n",
    "    stock_closes_rolling_avg = stock_closes_rolling_avg.fillna(method='bfill')  \n",
    "    stock_closes_rolling_avg =  list(stock_closes_rolling_avg.values)\n",
    "\n",
    "    for cnt in range(4, len(stock_closes)):\n",
    "        print(cnt)\n",
    "        if (cnt % 500 == 0): \n",
    "            print('\\tfinished processing {} trading dates for stock {}'.format(str(cnt), stock))\n",
    "\n",
    "        if (cnt >= TIME_RANGE):\n",
    "            # start making images\n",
    "                # np.round(x, 0) helps you to round x to the nearest EVEN value. \n",
    "                #      Thus 1.5 and 2.5 round to 2.0, -0.5 and 0.5 round to 0.0, etc.\n",
    "            graph_open = list(np.round(scale_list(stock_opens[cnt-TIME_RANGE:cnt], 0, half_scale_size-1),0))\n",
    "            graph_close_minus_open = list(np.round(scale_list(close_minus_open[cnt-TIME_RANGE:cnt], 0, half_scale_size-1),0))\n",
    "            \n",
    "            # scale both close and close MA toegher\n",
    "            # since we will put the close and close MA in the same TOP part of the image, we have to scale them together.\n",
    "            close_data_together = list(\n",
    "                np.round(\n",
    "                scale_list(\n",
    "                    list(stock_closes[cnt-TIME_RANGE:cnt]) + list(stock_closes_rolling_avg[cnt-TIME_RANGE:cnt])+list(stock_s10[cnt-TIME_RANGE:cnt]),\n",
    "                    0, half_scale_size-1\n",
    "                ),\n",
    "                0\n",
    "            )\n",
    "            )\n",
    "            graph_close = close_data_together[0:PRICE_RANGE]\n",
    "            graph_close_ma = close_data_together[PRICE_RANGE:] \n",
    "\n",
    "            outcome = None\n",
    "            if (cnt < len(stock_closes) -1):\n",
    "                outcome = 0\n",
    "                if stock_closes[cnt+1] > stock_closes_rolling_avg[cnt+1]:\n",
    "                    # we label the current Y (outcome） as 1 if the close price is greater \n",
    "                    # than the 6 days MA on the next trading day\n",
    "                    # 0 otherwise\n",
    "                    outcome = 1\n",
    "\n",
    "            blank_matrix_close = np.zeros(shape=(half_scale_size, TIME_RANGE))\n",
    "            x_ind = 0\n",
    "            for ma, c in zip(graph_close_ma, graph_close):\n",
    "                # you can treat the 1 and 2 are different colors\n",
    "                blank_matrix_close[int(ma), x_ind] = 1 \n",
    "                blank_matrix_close[int(c), x_ind] = 2  \n",
    "                x_ind += 1\n",
    "\n",
    "            # flip x scale dollars so high number is at top, low number at bottom - cosmetic, humans only\n",
    "            # double colons in numpy array matrix\n",
    "                # a = array([[1, 2], [3, 6], [4,5]])\n",
    "                # a:\n",
    "                #    1 2\n",
    "                #    3 6\n",
    "                #    4 5\n",
    "                # since a starts with the left-top element, e.g. a[0, 0] == 1 instead of 4, we have to filp the matrix!!!!!\n",
    "                # a[::-1] = array([[4, 5], [3, 6], [1, 2]]): reverse the whole array\n",
    "            blank_matrix_close = blank_matrix_close[::-1]\n",
    "\n",
    "            # store image data into matrix DATA_SIZE*DATA_SIZE\n",
    "            blank_matrix_diff = np.zeros(shape=(half_scale_size, TIME_RANGE))\n",
    "            x_ind = 0\n",
    "            for v in graph_close_minus_open:\n",
    "                blank_matrix_diff[int(v), x_ind] = 3  \n",
    "                x_ind += 1\n",
    "            # flip x scale so high number is atop, low number at bottom - cosmetic, humans only\n",
    "            blank_matrix_diff = blank_matrix_diff[::-1]\n",
    "\n",
    "            # stack vertically for two matrixes\n",
    "            blank_matrix = np.vstack([blank_matrix_close, blank_matrix_diff]) \n",
    "\n",
    "            need_plot=False\n",
    "            if need_plot:\n",
    "                # graphed on matrix\n",
    "                plt.imshow(blank_matrix)\n",
    "                plt.show()\n",
    "\n",
    "                # straight timeseries \n",
    "                plt.plot(graph_close, color='black')\n",
    "                plt.show()\n",
    "\n",
    "            if (outcome == None):\n",
    "                # live data\n",
    "                if x_live is None:\n",
    "                    x_live =[blank_matrix]\n",
    "                else:\n",
    "                    x_live = np.vstack([x_live, [blank_matrix]])\n",
    "                live_symbols.append(stock)\n",
    "\n",
    "            elif (stock_dates[cnt] >= VALIDTAION_CUTOFF_DATE):\n",
    "                # validation data\n",
    "                if x_valid is None:\n",
    "                    x_valid = [blank_matrix]\n",
    "                else:\n",
    "                    x_valid = np.vstack([x_valid, [blank_matrix]])\n",
    "                y_valid.append(outcome)\n",
    "\n",
    "            else:\n",
    "                # training data\n",
    "                if x_train is None:\n",
    "                    x_train = [blank_matrix]\n",
    "                else:\n",
    "                    x_train = np.vstack([x_train, [blank_matrix]])\n",
    "                y_train.append(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_mod shape: (1790, 20, 20, 1)\n",
      "x_valid shape: (680, 20, 20, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1790 samples, validate on 1790 samples\n",
      "Epoch 1/5\n",
      "1790/1790 [==============================] - 1s 769us/step - loss: 0.6808 - accuracy: 0.5838 - val_loss: 0.6608 - val_accuracy: 0.5899\n",
      "Epoch 2/5\n",
      "1790/1790 [==============================] - 1s 702us/step - loss: 0.6542 - accuracy: 0.6084 - val_loss: 0.6231 - val_accuracy: 0.6587\n",
      "Epoch 3/5\n",
      "1790/1790 [==============================] - 1s 718us/step - loss: 0.6269 - accuracy: 0.6587 - val_loss: 0.5810 - val_accuracy: 0.6894\n",
      "Epoch 4/5\n",
      "1790/1790 [==============================] - 1s 775us/step - loss: 0.5946 - accuracy: 0.6888 - val_loss: 0.5427 - val_accuracy: 0.7469\n",
      "Epoch 5/5\n",
      "1790/1790 [==============================] - 1s 804us/step - loss: 0.5485 - accuracy: 0.7207 - val_loss: 0.4928 - val_accuracy: 0.7877\n",
      "balance 0.58938545\n",
      "valid auc: 0.563140368852459\n",
      "Accuracy on all data: 0.5794117647058824\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 100\n",
    "num_classes = 2\n",
    "epochs = 5\n",
    " \n",
    "# input image dimensions\n",
    "img_rows, img_cols = TIME_RANGE, TIME_RANGE\n",
    "\n",
    "# add fake depth channel \n",
    "x_train_mod = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)#(1790, 20, 20, 1)\n",
    "# print(x_train)\n",
    "# print(x_train_mod)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (TIME_RANGE, TIME_RANGE, 1)\n",
    "\n",
    "x_train_mod = x_train_mod.astype('float32')\n",
    "x_valid = x_valid.astype('float32')\n",
    "\n",
    "print('x_train_mod shape:', x_train_mod.shape)\n",
    "print('x_valid shape:', x_valid.shape)\n",
    "\n",
    "# https://keras.io/zh/utils/\n",
    "# to_categorical: one-hot encoding\n",
    "y_train_mod = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid_mod = keras.utils.to_categorical(y_valid, num_classes)\n",
    "\n",
    "# ref: https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), input_shape=input_shape, activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(10, (2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_mod, y_train_mod,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_train_mod, y_train_mod))\n",
    " \n",
    "\n",
    "score = model.evaluate(x_train_mod, y_train_mod, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    " \n",
    "predictions = model.predict(x_valid)\n",
    "\n",
    "# run an accuracy or auc test\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    " \n",
    "# balance\n",
    "print('balance', np.mean(y_train_mod[:,1]))\n",
    "fpr, tpr, thresholds = roc_curve(y_valid_mod[:,1], predictions[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('valid auc:',roc_auc)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.legend()\n",
    "\n",
    "actuals = y_valid_mod[:,1]\n",
    "preds = predictions[:,1]\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('Accuracy on all data:', accuracy_score(actuals,[1 if x >= 0.5 else 0 for x in preds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on higher threshold: 0.7697841726618705\n",
      "Returns: 278\n"
     ]
    }
   ],
   "source": [
    "# Lets' Run with The Best Bets\n",
    "threshold = 0.65\n",
    "preds = predictions[:,1][predictions[:,1] >= threshold]\n",
    "actuals = y_valid_mod[:,1][predictions[:,1] >= threshold]\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('Accuracy on higher threshold:', accuracy_score(actuals,[1 if x > 0.5 else 0 for x in preds]))\n",
    "print('Returns:',len(actuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid auc: 0.563140368852459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ae34973c08>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_valid_mod[:,1], predictions[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('valid auc:',roc_auc)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            macro avg  weighted avg\n",
      "precision    0.508655      0.602155\n",
      "recall       0.509520      0.579412\n",
      "f1-score     0.507396      0.589383\n",
      "support    680.000000    680.000000\n",
      "                 0\n",
      "accuracy  0.579412\n",
      "AUC       0.563140\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "result = get_performance(report,roc_auc,accuracy_score(actuals,[1 if x > 0.5 else 0 for x in preds]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.5916200995445251 using {'batch_size': 1000, 'epochs': 5}\n",
      "0.591620 (0.019545) with: {'batch_size': 1000, 'epochs': 5}\n"
     ]
    }
   ],
   "source": [
    "# Batch size, number of epochs\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape, activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(10, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# model.fit(x_train_mod, y_train_mod,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_train_mod, y_train_mod))\n",
    " \n",
    "# 创建模型\n",
    "model = scikit_learn.KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# 设置参数候选值\n",
    "batch_size = [1000]\n",
    "epochs = [5]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "# init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "# init_mode = ['uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "\n",
    "\n",
    "\n",
    "# 创建GridSearchCV，并训练\n",
    "param_grid = dict(batch_size=batch_size,epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(x_train_mod, y_train_mod)\n",
    "\n",
    "# score = model.evaluate(x_train_mod, y_train_mod, verbose=0)\n",
    "# # print('Test loss:', score[0])\n",
    "# # print('Test accuracy:', score[1])\n",
    " \n",
    "# predictions = model.predict(x_valid)\n",
    " \n",
    "# 打印结果\n",
    "print('Best: {} using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    " \n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, std, param))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1432/1432 [==============================] - 2s 1ms/step - loss: 0.6814 - accuracy: 0.5817\n",
      "358/358 [==============================] - 0s 281us/step\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1432/1432 [==============================] - 2s 1ms/step - loss: 0.6788 - accuracy: 0.5852\n",
      "358/358 [==============================] - 0s 383us/step\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1432/1432 [==============================] - 2s 1ms/step - loss: 0.6801 - accuracy: 0.5796: 0s - loss: 0.6797 - accuracy: 0.\n",
      "358/358 [==============================] - 0s 343us/step\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1432/1432 [==============================] - 2s 1ms/step - loss: 0.6776 - accuracy: 0.5831\n",
      "358/358 [==============================] - 0s 318us/step\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1432/1432 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5922\n",
      "358/358 [==============================] - 0s 332us/step\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1432/1432 [==============================] - 2s 1ms/step - loss: 0.6712 - accuracy: 0.5985\n",
      "358/358 [==============================] - 0s 284us/step\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1432/1432 [==============================] - 2s 1ms/step - loss: 0.6702 - accuracy: 0.5908\n",
      "358/358 [==============================] - 0s 436us/step\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1432/1432 [==============================] - 2s 1ms/step - loss: 0.6724 - accuracy: 0.5950\n",
      "358/358 [==============================] - 0s 293us/step\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1432/1432 [==============================] - 2s 1ms/step - loss: 0.6705 - accuracy: 0.5999\n",
      "358/358 [==============================] - 0s 337us/step\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1432/1432 [==============================] - 2s 1ms/step - loss: 0.6717 - accuracy: 0.5943\n",
      "358/358 [==============================] - 0s 337us/step\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1790/1790 [==============================] - 2s 1ms/step - loss: 0.6735 - accuracy: 0.5888\n",
      "Best: 0.6039106130599976 using {'optimizer': 'RMSprop'}\n",
      "0.589385 (0.025904) with: {'optimizer': 'SGD'}\n",
      "0.603911 (0.042487) with: {'optimizer': 'RMSprop'}\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "def create_model(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape, activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(10, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# model.fit(x_train_mod, y_train_mod,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_train_mod, y_train_mod))\n",
    " \n",
    "# 创建模型\n",
    "model = scikit_learn.KerasClassifier(build_fn=create_model, epochs=1, batch_size=16, verbose=1)\n",
    "\n",
    "# 设置参数候选值\n",
    "optimizer = ['SGD', 'RMSprop']\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "# init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "# init_mode = ['uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "\n",
    "\n",
    "\n",
    "# 创建GridSearchCV，并训练\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(x_train_mod, y_train_mod)\n",
    "\n",
    "# score = model.evaluate(x_train_mod, y_train_mod, verbose=0)\n",
    "# # print('Test loss:', score[0])\n",
    "# # print('Test accuracy:', score[1])\n",
    " \n",
    "# predictions = model.predict(x_valid)\n",
    " \n",
    "# 打印结果\n",
    "print('Best: {} using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    " \n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, std, param))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1790/1790 [==============================] - 2s 1ms/step - loss: 0.6884 - accuracy: 0.5732\n",
      "Best: 0.5117599666118622 using {'init_mode': 'uniform'}\n",
      "0.511760 (0.091328) with: {'init_mode': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# weight initialization\n",
    "def create_model(init_mode='uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape, kernel_initializer=init_mode,activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), kernel_initializer=init_mode,activation='relu'))\n",
    "    model.add(Conv2D(10, (2, 2), kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dense(50,kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer=init_mode,activation='softmax'))\n",
    "    # Compile model\n",
    "    optimizer = SGD(lr=1)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# model.fit(x_train_mod, y_train_mod,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_train_mod, y_train_mod))\n",
    " \n",
    "# 创建模型\n",
    "model = scikit_learn.KerasClassifier(build_fn=create_model, epochs=1, batch_size=16, verbose=1)\n",
    "\n",
    "# 设置参数候选值\n",
    "# learn_rate = [0.001, 0.01]\n",
    "# init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "# init_mode = ['uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "init_mode = ['uniform']\n",
    "\n",
    "\n",
    "# 创建GridSearchCV，并训练\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(x_train_mod, y_train_mod)\n",
    "\n",
    "# score = model.evaluate(x_train_mod, y_train_mod, verbose=0)\n",
    "# # print('Test loss:', score[0])\n",
    "# # print('Test accuracy:', score[1])\n",
    " \n",
    "# predictions = model.predict(x_valid)\n",
    " \n",
    "# 打印结果\n",
    "print('Best: {} using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    " \n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, std, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "453/453 [==============================] - 0s 974us/step - loss: 0.5836 - accuracy: 0.7461\n",
      "227/227 [==============================] - 0s 220us/step\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "453/453 [==============================] - 1s 1ms/step - loss: 0.6246 - accuracy: 0.6976\n",
      "227/227 [==============================] - 0s 220us/step\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "454/454 [==============================] - 1s 1ms/step - loss: 0.6250 - accuracy: 0.6960\n",
      "226/226 [==============================] - 0s 295us/step\n",
      "CV Score = 0.7177108104947175\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.6579\n",
      "226/226 [==============================] - 0s 207us/step\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "454/454 [==============================] - 1s 1ms/step - loss: 0.6247 - accuracy: 0.6938\n",
      "226/226 [==============================] - 0s 243us/step\n",
      "Time Series CV Score = 0.747787610619469\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "115/115 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5826\n",
      "113/113 [==============================] - 0s 381us/step\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6404\n",
      "113/113 [==============================] - 0s 371us/step\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "341/341 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6628\n",
      "113/113 [==============================] - 0s 307us/step\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "454/454 [==============================] - 0s 973us/step - loss: 0.6219 - accuracy: 0.6850\n",
      "113/113 [==============================] - 0s 282us/step\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5978 - accuracy: 0.7260\n",
      "113/113 [==============================] - 0s 296us/step\n",
      "Time Series(max_train_size=500) CV Score = 0.6407079646017699\n"
     ]
    }
   ],
   "source": [
    "# CV-test\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "cross_val = cross_val_score(model, x_valid, y_valid_mod[:,1], scoring='accuracy', cv=3)\n",
    "print('CV Score =',cross_val.mean())\n",
    "cross_val = cross_val_score(model, x_valid, y_valid_mod[:,1], scoring='accuracy', cv=TimeSeriesSplit(n_splits=2))\n",
    "print('Time Series CV Score =',cross_val.mean())\n",
    "cross_val = cross_val_score(model, x_valid, y_valid_mod[:,1], scoring='accuracy', cv=TimeSeriesSplit(max_train_size=500))\n",
    "print('Time Series(max_train_size=500) CV Score =',cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            macro avg  weighted avg\n",
      "precision    0.508655      0.602155\n",
      "recall       0.509520      0.579412\n",
      "f1-score     0.507396      0.589383\n",
      "support    680.000000    680.000000\n",
      "                 0\n",
      "accuracy  0.579412\n",
      "AUC       0.563140\n"
     ]
    }
   ],
   "source": [
    "report2=get_performance(report,roc_auc,accuracy_score(actuals,[1 if x > 0.5 else 0 for x in preds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN performs the best for my dataset.\n",
      "Daily Stock: AAPL,AXP,BA,CAT,CSCO from 2016-01-01 to 2018-01-17\n",
      "With the accuracy:0.512, precision:0.602, recall:0.579, f1:0.589, auc:0.563,CV-score:0.641\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d,e,f=grid_result.best_score_,report2.iloc[0][1],report2.iloc[1][1],report2.iloc[2][1],roc_auc,cross_val.mean()\n",
    "f1=\"CNN\"\n",
    "start=\"2016-01-01\"\n",
    "end=\"2018-01-17\"\n",
    "print(\"%s performs the best for my dataset.\" % (f1))\n",
    "print(\"Daily \"+ 'Stock: AAPL,AXP,BA,CAT,CSCO from '+start+ ' to ' +end+ \"\\nWith the accuracy:%.3f, precision:%.3f, recall:%.3f, f1:%.3f, auc:%.3f,CV-score:%.3f\" % (a,b,c,d,e,f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best parameters are: using {'batch_size': 1000, 'epochs': 5}, using{'optimizer': 'RMSprop'},using {'init_mode': 'uniform'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
